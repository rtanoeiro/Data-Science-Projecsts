{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my first dataset that uses Plotly after studying for a few days. If you like these visualisations, please give me a upvote or leave a comment, so I can see they're appropriate :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset deals with air pollution measurement information in Seoul, South Korea.\n",
    "Seoul Metropolitan Government provides many public data, including air pollution information, through the 'Open Data Plaza'\n",
    "I made a structured dataset by collecting and adjusting various air pollution related datasets provided by the Seoul Metropolitan Government\n",
    "\n",
    "Content\n",
    "This data provides average values for six pollutants (SO2, NO2, CO, O3, PM10, PM2.5).\n",
    "\n",
    "Data were measured every hour between 2017 and 2019.\n",
    "Data were measured for 25 districts in Seoul.\n",
    "This dataset is divided into four files.\n",
    "Measurement info: Air pollution measurement information\n",
    "\n",
    "1 hour average measurement is provided after calibration\n",
    "Instrument status:\n",
    "0: Normal, 1: Need for calibration, 2: Abnormal\n",
    "4: Power cut off, 8: Under repair, 9: abnormal data\n",
    "Measurement item info: Information on air pollution measurement items\n",
    "\n",
    "Measurement station info: Information on air pollution instrument stations\n",
    "\n",
    "Measurement summary: A condensed dataset based on the above three data.\n",
    "\n",
    "Acknowledgements\n",
    "Data is provided from here.\n",
    "\n",
    "https://data.seoul.go.kr/dataList/OA-15526/S/1/datasetView.do\n",
    "https://data.seoul.go.kr/dataList/OA-15516/S/1/datasetView.do\n",
    "https://data.seoul.go.kr/dataList/OA-15515/S/1/datasetView.do\n",
    "Thank you to Seoul City, Seoul Open Data Plaza, and Air Quality Analysis Center for providing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "## Reading our data\n",
    "\n",
    "df = pd.read_csv(\"Measurement_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Measurement date</th>\n",
       "      <th>Station code</th>\n",
       "      <th>Address</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>CO</th>\n",
       "      <th>PM10</th>\n",
       "      <th>PM2.5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-01 00:00</td>\n",
       "      <td>101</td>\n",
       "      <td>19, Jong-ro 35ga-gil, Jongno-gu, Seoul, Republ...</td>\n",
       "      <td>37.572016</td>\n",
       "      <td>127.005008</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.2</td>\n",
       "      <td>73.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01 01:00</td>\n",
       "      <td>101</td>\n",
       "      <td>19, Jong-ro 35ga-gil, Jongno-gu, Seoul, Republ...</td>\n",
       "      <td>37.572016</td>\n",
       "      <td>127.005008</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.2</td>\n",
       "      <td>71.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-01-01 02:00</td>\n",
       "      <td>101</td>\n",
       "      <td>19, Jong-ro 35ga-gil, Jongno-gu, Seoul, Republ...</td>\n",
       "      <td>37.572016</td>\n",
       "      <td>127.005008</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-01-01 03:00</td>\n",
       "      <td>101</td>\n",
       "      <td>19, Jong-ro 35ga-gil, Jongno-gu, Seoul, Republ...</td>\n",
       "      <td>37.572016</td>\n",
       "      <td>127.005008</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-01-01 04:00</td>\n",
       "      <td>101</td>\n",
       "      <td>19, Jong-ro 35ga-gil, Jongno-gu, Seoul, Republ...</td>\n",
       "      <td>37.572016</td>\n",
       "      <td>127.005008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.2</td>\n",
       "      <td>69.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Measurement date  Station code  \\\n",
       "0  2017-01-01 00:00           101   \n",
       "1  2017-01-01 01:00           101   \n",
       "2  2017-01-01 02:00           101   \n",
       "3  2017-01-01 03:00           101   \n",
       "4  2017-01-01 04:00           101   \n",
       "\n",
       "                                             Address   Latitude   Longitude  \\\n",
       "0  19, Jong-ro 35ga-gil, Jongno-gu, Seoul, Republ...  37.572016  127.005008   \n",
       "1  19, Jong-ro 35ga-gil, Jongno-gu, Seoul, Republ...  37.572016  127.005008   \n",
       "2  19, Jong-ro 35ga-gil, Jongno-gu, Seoul, Republ...  37.572016  127.005008   \n",
       "3  19, Jong-ro 35ga-gil, Jongno-gu, Seoul, Republ...  37.572016  127.005008   \n",
       "4  19, Jong-ro 35ga-gil, Jongno-gu, Seoul, Republ...  37.572016  127.005008   \n",
       "\n",
       "     SO2    NO2     O3   CO  PM10  PM2.5  \n",
       "0  0.004  0.059  0.002  1.2  73.0   57.0  \n",
       "1  0.004  0.058  0.002  1.2  71.0   59.0  \n",
       "2  0.004  0.056  0.002  1.2  70.0   59.0  \n",
       "3  0.004  0.056  0.002  1.2  70.0   58.0  \n",
       "4  0.003  0.051  0.002  1.2  69.0   61.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Checking our data\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 647511 entries, 0 to 647510\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   Measurement date  647511 non-null  object \n",
      " 1   Station code      647511 non-null  int64  \n",
      " 2   Address           647511 non-null  object \n",
      " 3   Latitude          647511 non-null  float64\n",
      " 4   Longitude         647511 non-null  float64\n",
      " 5   SO2               647511 non-null  float64\n",
      " 6   NO2               647511 non-null  float64\n",
      " 7   O3                647511 non-null  float64\n",
      " 8   CO                647511 non-null  float64\n",
      " 9   PM10              647511 non-null  float64\n",
      " 10  PM2.5             647511 non-null  float64\n",
      "dtypes: float64(8), int64(1), object(2)\n",
      "memory usage: 54.3+ MB\n"
     ]
    }
   ],
   "source": [
    "## Checking type of columns\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains  25 different addresses\n",
      "The dataset contains  25 different Latitudes\n",
      "The dataset contains  25 different Longitudes\n"
     ]
    }
   ],
   "source": [
    "table = df.Address.groupby(df.Address, as_index=True)\n",
    "print(\"The dataset contains \",len(table), \"different addresses\")\n",
    "table1 = df.Latitude.groupby(df.Latitude, as_index=True)\n",
    "print(\"The dataset contains \",len(table1), \"different Latitudes\")\n",
    "table2 = df.Longitude.groupby(df.Longitude, as_index=True)\n",
    "print(\"The dataset contains \",len(table2), \"different Longitudes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping columns that won't affect our visualisations, this will help decrease the dataset size\n",
    "df.drop([\"Address\", \"Latitude\", \"Longitude\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting our column to date, as the column was an object tyoe\n",
    "df['Measurement date'] = pd.to_datetime(df['Measurement date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SO2</th>\n",
       "      <th>NO2</th>\n",
       "      <th>CO</th>\n",
       "      <th>O3</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Good</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2</td>\n",
       "      <td>0.03</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>9</td>\n",
       "      <td>0.09</td>\n",
       "      <td>35</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bad</th>\n",
       "      <td>0.15</td>\n",
       "      <td>0.20</td>\n",
       "      <td>15</td>\n",
       "      <td>0.15</td>\n",
       "      <td>75</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very Bad</th>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>500</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SO2   NO2  CO    O3  PM2.5  PM10\n",
       "Good      0.02  0.03   2  0.03     15    30\n",
       "Normal    0.05  0.06   9  0.09     35    80\n",
       "Bad       0.15  0.20  15  0.15     75   150\n",
       "Very Bad  1.00  2.00  50  0.50    500   600"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating a table to see the standard values for good and bad air quality\n",
    "\n",
    "polluents = {'SO2':[0.02,0.05,0.15,1],'NO2':[0.03,0.06,0.2,2],'CO':[2,9,15,50],'O3':[0.03,0.09,0.15,0.5],'PM2.5':[15,35,75,500],'PM10':[30,80,150,600]}\n",
    "quality = ['Good','Normal','Bad','Very Bad']\n",
    "seoul_standard = pd.DataFrame(polluents, index=quality)\n",
    "seoul_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##conda install openpyxl \n",
    "## !pip install xlsxwriter\n",
    "## remove comment if you need to install excel package to write a excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now I'm gonna automate the preprocessing of the data for each dataframe and save into a excel_file\n",
    "## Each Sheet of this Excel file is a station.\n",
    "\n",
    "## Creating a dataframe for each station code\n",
    "\n",
    "df_101 = pd.DataFrame(df.loc[(df['Station code']==101)])\n",
    "df_102 = pd.DataFrame(df.loc[(df['Station code']==102)])\n",
    "df_103 = pd.DataFrame(df.loc[(df['Station code']==103)])\n",
    "df_104 = pd.DataFrame(df.loc[(df['Station code']==104)])\n",
    "df_105 = pd.DataFrame(df.loc[(df['Station code']==105)])\n",
    "df_106 = pd.DataFrame(df.loc[(df['Station code']==106)])\n",
    "df_107 = pd.DataFrame(df.loc[(df['Station code']==107)])\n",
    "df_108 = pd.DataFrame(df.loc[(df['Station code']==108)])\n",
    "df_109 = pd.DataFrame(df.loc[(df['Station code']==109)])\n",
    "df_110 = pd.DataFrame(df.loc[(df['Station code']==110)])\n",
    "df_111 = pd.DataFrame(df.loc[(df['Station code']==111)])\n",
    "df_112 = pd.DataFrame(df.loc[(df['Station code']==112)])\n",
    "df_113 = pd.DataFrame(df.loc[(df['Station code']==113)])\n",
    "df_114 = pd.DataFrame(df.loc[(df['Station code']==114)])\n",
    "df_115 = pd.DataFrame(df.loc[(df['Station code']==115)])\n",
    "df_116 = pd.DataFrame(df.loc[(df['Station code']==116)])\n",
    "df_117 = pd.DataFrame(df.loc[(df['Station code']==117)])\n",
    "df_118 = pd.DataFrame(df.loc[(df['Station code']==118)])\n",
    "df_119 = pd.DataFrame(df.loc[(df['Station code']==119)])\n",
    "df_120 = pd.DataFrame(df.loc[(df['Station code']==120)])\n",
    "df_121 = pd.DataFrame(df.loc[(df['Station code']==121)])\n",
    "df_122 = pd.DataFrame(df.loc[(df['Station code']==122)])\n",
    "df_123 = pd.DataFrame(df.loc[(df['Station code']==123)])\n",
    "df_124 = pd.DataFrame(df.loc[(df['Station code']==124)])\n",
    "df_125 = pd.DataFrame(df.loc[(df['Station code']==125)])\n",
    "\n",
    "dfs = [df_101, df_102, df_103, df_104, df_105, df_106, df_107, df_108, df_109,\n",
    "       df_110, df_111, df_112, df_113, df_114, df_115, df_116, df_117, df_118,\n",
    "       df_119, df_120, df_121, df_122, df_123, df_124, df_125]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaning the data in the dataset\n",
    "\n",
    "for dataset in dfs:\n",
    "    \n",
    "    dataset.drop('Station code', axis=1, inplace=True)\n",
    "    \n",
    "    to_drop = dataset.loc[(dataset['SO2']<=0) | (dataset['NO2']<=0) | (dataset['CO']<=0) | (dataset['O3']<=0) |\n",
    "                          (dataset['PM2.5']<=0) | (dataset['PM10']<=0)\n",
    "                         ]\n",
    "    ## This will iterate over all dfs from all station codes, and clean all negative or 0 values for all columns\n",
    "    ## We'll also drop the Station Code column, as we'll create several sheets for them.\n",
    "    dataset.drop(to_drop.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 101\n",
    "\n",
    "sheet_names = {}\n",
    "\n",
    "for j in dfs:\n",
    "    station = 'Station_'+str(i)\n",
    "    sheet_names.update({station:j})\n",
    "    i = i + 1\n",
    "    \n",
    "## We'll need a dictionary with our Station_x as key to be used as a sheet name\n",
    "## and the current df as a value. With this, we can iterate over this dictionary\n",
    "## and create a sheet with the station_x name and the data fom the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter('Station_Data.xlsx', engine='xlsxwriter')\n",
    "\n",
    "for name,frame in sheet_names.items(): ## Iterating over the created dictionary\n",
    "        \n",
    "    frame.to_excel(writer, sheet_name = name, startrow=1, header=False, index=False) \n",
    "    ## frame is our value of the dict. It's our current dataframe, name is our Key. As we iterate over this dict\n",
    "    ## the values will be name, frame = Station_101, df_101 -> Station_102, df_102 -> ... Station_125, df_125\n",
    "\n",
    "    # Get the xlsxwriter workbook and worksheet objects. *\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets[name]\n",
    "    \n",
    "    # Get the dimensions of the dataframe.*\n",
    "    (max_row, max_col) = frame.shape\n",
    "\n",
    "    # Create a list of column headers, to use in add_table(). *\n",
    "    column_settings = [{'header': column} for column in frame.columns]\n",
    "\n",
    "    # Add the Excel table structure. Pandas will add the data. *\n",
    "    worksheet.add_table(0, 0, max_row, max_col - 1, {'columns': column_settings})\n",
    "\n",
    "    # Make the columns wider for clarity. *\n",
    "    worksheet.set_column(0, max_col - 1, 12)\n",
    "    \n",
    "    ## The comments and code for the lines with * were taken from\n",
    "    ## https://xlsxwriter.readthedocs.io/example_pandas_table.html#ex-pandas-table\n",
    "    ## This guide help to create a formated table \n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
